{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParaView Batch example notebook\n",
    "\n",
    "In this notebook we will explore running ParaView in batch mode on Cooley.\n",
    "\n",
    "\n",
    "Let's assume that we have a time series of data files, and we want to generate an animation of that time series. \n",
    "* We would first run ParaView in interactive mode and set up our visualization pipeline, adding desired filters, etc.\n",
    "* Once our pipeline is all set we can save the state as a Python script\n",
    " * File->Save State -> filename.py\n",
    "\n",
    "There's an example state file named: **blood_flow_state_01.py**\n",
    "\n",
    "Let's take a look at that first...\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "\n",
    "Now, we can run ParaView in batch mode (pvbatch), and pass it that Python script to render a set of frames from that time series.\n",
    "\n",
    "Our test data set is pretty small, but you can imagine wanting to do this for a much larger data set.  In which case, it would be useful to be able to have multiple jobs processing different sets of frames at the same time, in order to reduce the overall wait time.\n",
    "\n",
    "So, we will submit multiple jobs to run  pvbatch and render different sets of frames.\n",
    "\n",
    "Once all of the frames are complete, we can encode these frames into a video using ffmpeg.\n",
    "\n",
    "Finally, we will show the resulting video and embed it in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths and filenames\n",
    "\n",
    "Create a directory on your home directory for frames and videos and point *framesDir* variable to it\n",
    "\n",
    "We also specify the path to our ParaView Python state file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_login=\"hyunlim\"\n",
    "\n",
    "framesDir=\"/home/\" + my_login + \"/atpesc/viz/jupyter-ATPESC2018/pv_blood_flow/frames/\"\n",
    "videoFileName=\"video.mp4\"\n",
    "\n",
    "pv_script=\"/home/\" + my_login + \"/atpesc/viz/jupyter-ATPESC2018/pv_blood_flow/blood_flow_state_01.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our example data set has 100 time steps.  So we'll set the total number of frames. In a minute we're going to submit two jobs, each will render half of the time steps.  So, we'll also set the number of half of the frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_frames_half:  50\n"
     ]
    }
   ],
   "source": [
    "start_frame = 0\n",
    "num_frames = 100\n",
    "num_frames_half = int(num_frames/2)\n",
    "print (\"num_frames_half: \" , num_frames_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up directory containing frames. \n",
    "\n",
    "Think carefully before running. You may not want to delete frames from a previous run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames directory was empty\r\n"
     ]
    }
   ],
   "source": [
    "! [ -e \"$framesDir/frame_\"0000.png ] && rm \"$framesDir/frame_\"*png && echo \"previous frames deleted\" || echo \"frames directory was empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to make sure frames directory is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2\r\n",
      "drwxr-xr-x 2 hyunlim users  512 Aug  9 20:30 .\r\n",
      "drwxr-xr-x 4 hyunlim users 1024 Aug  9 21:54 ..\r\n",
      "-rw-r--r-- 1 hyunlim users    0 Aug  9 20:30 .empty\r\n"
     ]
    }
   ],
   "source": [
    "! ls -la \"$framesDir\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're going to be submitting jobs to the queue on Cooley, we'll need to tell it what project to charge and what queue to use.  We'll also set our login name, so that we can check on our jobs in the queue once we submit them.\n",
    "\n",
    "During our reservation these values should be set to:\n",
    "\n",
    "* my_project = **\"ATPESC2018\"**\n",
    "* queue = **\"training\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_project=\"ATPESC2018\"\n",
    "queue=\"training\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a batch script, passing it all of the relevant information.  That script will submit two jobs, one to render the first half of our frames, and another to render the second half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATPESC2018 training /home/hyunlim/atpesc/viz/jupyter-ATPESC2018/pv_blood_flow/blood_flow_state_01.py 0 50 /home/hyunlim/atpesc/viz/jupyter-ATPESC2018/pv_blood_flow/frames/\n",
      "1611097\n",
      "1611098\n"
     ]
    }
   ],
   "source": [
    "%%bash -s  \"$my_project\" \"$queue\" \"$pv_script\" \"$start_frame\" \"$num_frames_half\" \"$framesDir\" \n",
    "echo $1 $2 $3 $4 $5 $6\n",
    "/bin/qsub -n 1 -t 30 -A $1 -q $2 --env DISPLAY=:0.0 /soft/visualization/paraview/v5.5.2/bin/pvbatch $3 $4 $5 $6\n",
    "/bin/qsub -n 1 -t 30 -A $1 -q $2 --env DISPLAY=:0.0 /soft/visualization/paraview/v5.5.2/bin/pvbatch $3 $5 $5 $6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've run the above script, we can check the queue to see the state of our jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobID    JobName  User     Score    WallTime  QueuedTime  RunTime   Nodes  State     Location      Mode    Procs  Queue     StartTime                             \r\n",
      "==================================================================================================================================================================\r\n",
      "1611097  N/A      hyunlim    0.5    00:30:00  00:00:42    00:00:33  1      exiting   cc102.cooley  script  1      training  Thu Aug 09 21:59:10 2018 +0000 (UTC)  \r\n",
      "1611098  N/A      hyunlim    0.7    00:30:00  00:01:12    00:00:02  1      starting  cc063.cooley  script  1      training  Thu Aug 09 21:59:41 2018 +0000 (UTC)  \r\n"
     ]
    }
   ],
   "source": [
    "! /bin/qstat -fu $my_login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check our frames directory to see how many of the frames have completed.  Once this reaches 100, we will be finished rendering.  If you then go back to the previous cell, and check the queue again, you should see your jobs exiting (or nothing if they have already finished exiting).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\r\n"
     ]
    }
   ],
   "source": [
    "! ls \"$framesDir\" | wc -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is an older version of your video file, delete.\n",
    "\n",
    "Again, think twice before running the next cell. You may not want to delete this file before copying it somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! [ -e \"$videoFileName\" ] && rm \"$videoFileName\" && echo \"previous video file deleted\" || echo \"no previous video file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate a video file now with ffmpeg. Let's use the frames generated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version N-90676-g876f9ac Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 4.8.1 (GCC)\n",
      "  configuration: --prefix=/projects/visualization/srizzi/ffmpeg/ffmpeg_build/ --pkg-config-flags=--static --extra-cflags=-I/projects/visualization/srizzi/ffmpeg/ffmpeg_build/include --extra-ldflags=-L/projects/visualization/srizzi/ffmpeg/ffmpeg_build/lib --extra-libs=-lpthread --extra-libs=-lm --bindir=/projects/visualization/srizzi/ffmpeg/ffmpeg_bin/ --enable-gpl --enable-libfreetype --enable-libx264 --enable-nonfree\n",
      "  libavutil      56. 13.100 / 56. 13.100\n",
      "  libavcodec     58. 17.100 / 58. 17.100\n",
      "  libavformat    58. 11.101 / 58. 11.101\n",
      "  libavdevice    58.  2.100 / 58.  2.100\n",
      "  libavfilter     7. 15.100 /  7. 15.100\n",
      "  libswscale      5.  0.102 /  5.  0.102\n",
      "  libswresample   3.  0.101 /  3.  0.101\n",
      "  libpostproc    55.  0.100 / 55.  0.100\n",
      "Input #0, image2, from '/home/hyunlim/atpesc/viz/jupyter-ATPESC2018/pv_blood_flow/frames//frame_%04d.png':\n",
      "  Duration: 00:00:04.00, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: png, rgb24(pc), 960x540, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mprofile High, level 3.1\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0m264 - core 155 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=17 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'video.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.11.101\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 960x540, q=-1--1, 25 fps, 12800 tbn, 25 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.17.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  166 fps=0.0 q=-1.0 Lsize=     352kB time=00:00:06.52 bitrate= 442.5kbits/s dup=66 drop=0 speed=7.76x    \n",
      "video:349kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.790366%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mframe I:1     Avg QP:16.87  size: 19167\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mframe P:50    Avg QP:21.52  size:  4993\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mframe B:115   Avg QP:22.75  size:   768\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mconsecutive B-frames:  1.2% 19.3%  0.0% 79.5%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mmb I  I16..4: 38.1% 47.6% 14.3%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mmb P  I16..4:  0.7%  2.4%  0.4%  P16..4: 19.7% 11.2%  4.9%  0.0%  0.0%    skip:60.7%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mmb B  I16..4:  0.1%  0.1%  0.0%  B16..8: 14.5%  1.6%  0.1%  direct: 0.3%  skip:83.4%  L0:42.3% L1:54.4% BI: 3.3%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0m8x8 transform intra:60.8% inter:75.0%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mcoded y,uvDC,uvAC intra: 24.3% 45.8% 29.2% inter: 2.9% 6.3% 2.8%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mi16 v,h,dc,p: 52% 17%  8% 23%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 15% 49%  3%  3%  3%  4%  2%  5%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 15% 27% 25%  8%  5%  4%  6%  4%  6%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mi8c dc,h,v,p: 56% 22% 11% 11%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mref P L0: 67.8% 10.1% 15.7%  6.5%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mref B L0: 90.9%  7.8%  1.3%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mref B L1: 99.0%  1.0%\n",
      "\u001b[1;36m[libx264 @ 0x3216900] \u001b[0mkb/s:430.28\n"
     ]
    }
   ],
   "source": [
    "! /soft/visualization/ffmpeg/ffmpeg -r 15 -i \"$framesDir\"/frame_%04d.png -pix_fmt yuv420p -r 25 \"$videoFileName\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we embed the video in HTML format so we can view it here! if all works \n",
    "we should see a video of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video controls> <source src=\"video.mp4\" type=\"video/mp4\"> </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules\n",
    "import io\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "# Embed the video using HTML\n",
    "HTML(data='<video controls> <source src=\"' + videoFileName + '\" type=\"video/mp4\"> </video>') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then I am done!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
